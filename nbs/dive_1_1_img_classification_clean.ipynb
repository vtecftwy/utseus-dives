{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vtecftwy/utseus-dives/blob/main/nbs/dive_1_1_img_classification_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf4374f8"
      },
      "source": [
        "<h1>Guided Dive</h1>\n",
        "<h1>Build your own image classifier with deep learning</h1>"
      ],
      "id": "bf4374f8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1911e1e"
      },
      "source": [
        "# Introduction\n",
        "This notebook guides you through the main steps required to build an image classifier, using deep learning model. It is based on what practitioners would do every day.\n",
        "\n",
        "For each step, you will see a short explanation in words, and the corresponding code allowing you to execute/run each step.\n",
        "\n",
        "If you have never coded before, simply run the provided code.\n",
        "\n",
        "If you are more experienced, or just more adventurous, go ahead and modify the code or write yours. Do no worry, whatever you do, you cannot dammage the original notebook or what other people are doing. Feel free to break things. At worst, you will have reload the original notebook again and start a new session.\n",
        "\n",
        "Follow all the steps one by one and you will build your own deep learning model."
      ],
      "id": "c1911e1e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d635b567"
      },
      "source": [
        "## Agenda for the guided dive:\n",
        "- 📘 **Anatomy of a deep learning application**\n",
        "- 📷 **Build your Computer Vision model**\n",
        "    - 📘 Introduction to the project\n",
        "    - 👨‍💻 Data processing, train model, evaluate model\n",
        "    - 👨‍💻 Improve model"
      ],
      "id": "d635b567"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b516d855"
      },
      "source": [
        "# 📘 Anatomy of a deep learning model"
      ],
      "id": "b516d855"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7fdafac"
      },
      "source": [
        "The main idea behind machine learning is to use **data** (inputs and solutions) to train a **model**.\n",
        "> <div align=\"center\" width=100%>  <img src=\"http://www.charlier-tang.com/guided-dive/resources/img/anatomy_dl_01.svg\" height=160px>  </div>\n",
        "\n",
        "**Deep learning** is one type of supervised machine learning which uses an architecture remotely inspired from biological neurons.\n",
        "> <div align=\"center\" width=100%><img src=\"http://www.charlier-tang.com/guided-dive/resources/img/aan-small.jpg\" height=300px></div>\n",
        "\n",
        "In the _training phase_, we use **data**, a specific artificial neural network **architecture** and an **optimization algorithm** to train the **model**. The training process give us learned **parameters**.\n",
        "<div align=\"center\" width=100%><img src=\"http://www.charlier-tang.com/guided-dive/resources/img/anatomy_dl_02.svg\" height=160px></div>\n",
        "\n",
        "Once we have a trained model (i.e. an **architecture** with **parameters**), we can use it to make prediction on **new data**.\n",
        "\n",
        "<div align=\"center\" width=100%><img src=\"http://www.charlier-tang.com/guided-dive/resources/img/anatomy_dl_03.svg\" height=160px></div>\n"
      ],
      "id": "e7fdafac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a65728d2"
      },
      "source": [
        "For this guided dive session, we will use a library called **fast.ai**. It provides state of the art implementation of deep learning, while also making it possible to access its power from a high level API (simple high level code). It is built on top of `pytorch` and `python`.\n",
        "\n",
        "<div align=\"left\" width=100%><a href=\"https://www.fast.ai/\"><img src=\" https://docs.google.com/uc?export=download&id=1A0kmDbMxFXDJ_TVGAku562V2zPiDrX_V\" width=15%></a></div>"
      ],
      "id": "a65728d2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SmW3jgkWq81"
      },
      "source": [
        "**The steps to train a model include:**\n",
        "1. **Collecting the data and preparing them so that the model can learn from them**\n",
        "2. **Selecting an architecture and creating a specific model using that architecture**\n",
        "3. **Training the model by \"feeding\" the data to the model. We will apply transfer learning**\n",
        "\n",
        "We will go through each of these steps."
      ],
      "id": "-SmW3jgkWq81"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50e0c1de"
      },
      "source": [
        "#### 🔎 Details on how each step is structured in the code (optional)"
      ],
      "id": "50e0c1de"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab30684d"
      },
      "source": [
        "\n",
        "1. Collecting the data: `DataBlock()`\n",
        "    - defines what type of data, e.g. `ImageBlock` and `CategoryBlock`\n",
        "    - define how the data is collected, e.g. get the image from a function that will look into a folder the return any image file\n",
        "    - define how to get the label names, e.g. class name/label name is the name of the folder where the images are\n",
        "    - some preprocessing to do for each image, e.g. resizing then all to a square image or fixed value\n",
        "```\n",
        "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
        "                    get_items=get_image_files,\n",
        "                    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "                    get_y=parent_label,\n",
        "                    item_tfms=Resize(128)\n",
        "                    )\n",
        "```\n"
      ],
      "id": "ab30684d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "947315e1"
      },
      "source": [
        "2. Indicate where the data are, e.g. a path to a specific folder: `dataloaders()`\n",
        "```\n",
        "dls = dblock.dataloaders(path)\n",
        "```\n"
      ],
      "id": "947315e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cdd6f5e"
      },
      "source": [
        "3. Create a model\n",
        "    - select a specific architecture (for image, CNN Resnet with 18 layers)\n",
        "    - in this case we use a pretrained model for general images\n",
        "    - use the data loaders created aboce `dls`\n",
        "    - specify metrics to see how the training evolve\n",
        "```\n",
        "learn = cnn_learner(dls, resnet18, metrics=[accuracy, Recall(), Precision()])\n"
      ],
      "id": "0cdd6f5e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef077693"
      },
      "source": [
        "4. Train the model\n",
        "    - train it for a given number of iterations (epochs)\n",
        "    - we have a pretrained model, so we only need to fine tune it\n",
        "```\n",
        "learn.fine_tune(5)\n",
        "```"
      ],
      "id": "ef077693"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90403b1e"
      },
      "source": [
        "#### 🔎 End of details"
      ],
      "id": "90403b1e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5873f103"
      },
      "source": [
        "#### 🔎 How to create your own notebook and execute code?\n",
        "If you are not familiar with Colab or hosted Jupyter notebooks, read this section."
      ],
      "id": "5873f103"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec5ffba7"
      },
      "source": [
        "This page is a hosted Jupyter notebook. This is a special tooks that allows to write a page with text and illustration but also to run specific code and see the result of your own code. This facility is made available by Kaggle, and provides this convenient space to learn deep learning or other machine learning techniques.\n",
        "\n",
        "\n",
        "**Step by step instructions**:\n",
        "1. You got to this page. You have started a notebook in read only mode. You can run it but if you make changes, you will not be able to save them. In the `File` menu, you should see command `Save a copy in Drive`. Select that command and it will create a copy of this notebook in a new window and also save it under your own gdrive. The default name will be `dl-guided-deep-dive-01-cv.ipynb` but you can change it at any time. This is **your version of the notebook**, You can run it and modify it.\n",
        "\n",
        "2. You have your own copy of the notebook and can run/execute code in it. One of the advantages of Colab is that you have access to GPU computing capabilities (useful to accelerate computer vision models). To get the GPU, see `Change runtime type` in the `Runtime` menu. Select GPU if it is not already done.\n",
        "\n",
        "    > Once your new notebook is active, you have access to your own computing and storage capacity on a computer in the cloud. It is available to you for a few hours and will stay active unless you do not do anything for 15-30 min or so."
      ],
      "id": "ec5ffba7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMyORPPfGGRi"
      },
      "source": [
        "#### 🔎 End of details"
      ],
      "id": "qMyORPPfGGRi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce901f43"
      },
      "source": [
        "# 🧰 Imports and configurations\n",
        "Just run the cells in this section to get ready. Do not worry about the code here."
      ],
      "id": "ce901f43"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from nb_guided_dive.vision import *\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -Uqq git+https://github.com/vtecftwy/nb-guided-dive.git\n",
        "    from nb_guided_dive.vision import *\n",
        "try:\n",
        "    from duckduckgo_search import DDGS\n",
        "except:\n",
        "    print('installing duckduckgo_search package')\n",
        "    !pip install -qq duckduckgo_search\n",
        "    from duckduckgo_search import DDGS\n",
        "    print('duckduckgo_search package installed')\n",
        "try:\n",
        "    from jmd_imagescraper.imagecleaner import display_image_cleaner\n",
        "except:\n",
        "    print('installing jmd_imagescraper package')\n",
        "    !pip install -qq jmd_imagescraper\n",
        "    from jmd_imagescraper.imagecleaner import display_image_cleaner\n",
        "    print('jmd_imagescraper package installed')"
      ],
      "metadata": {
        "id": "3EciXFUIidfC"
      },
      "id": "3EciXFUIidfC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from duckduckgo_search import DDGS\n",
        "from fastprogress.fastprogress import progress_bar\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from shutil import rmtree\n",
        "from fastai import __version__\n",
        "from fastai.vision.all import *\n",
        "from fastai.vision.utils import download_images\n",
        "from fastai.vision.widgets import ImagesCleaner , ImageClassifierCleaner\n",
        "\n",
        "print(f\"fastai version {__version__}\")"
      ],
      "metadata": {
        "id": "kbOfNDj2wp78"
      },
      "id": "kbOfNDj2wp78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jtusrDfBVCA"
      },
      "outputs": [],
      "source": [
        "config_fastai_for_colab()"
      ],
      "id": "5jtusrDfBVCA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24e8e15d"
      },
      "source": [
        "# 📷 Computer Vision: Steps to Build an Image Classifier"
      ],
      "id": "24e8e15d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64fa7c1f"
      },
      "outputs": [],
      "source": [
        "ml_process()"
      ],
      "id": "64fa7c1f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6609991f"
      },
      "source": [
        "## 1️⃣ Frame the problem"
      ],
      "id": "6609991f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f3cd0bc"
      },
      "source": [
        "This is the moment when we analyse the problem at hand in details to make sure that we are not spending time and resources on something that is not what is required. We will learn all about this on Wednesday. For the moment, let's says that:\n",
        "- We have a large number of lemons to ship everyday. They are manually sorted on conveyor belt.\n",
        "- We want to add a camera above teh conveyor belt and feed a system that will indicate whether a lemon is OK or NOT.\n"
      ],
      "id": "2f3cd0bc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb45ec2c"
      },
      "source": [
        "### What we have:\n",
        "- A conveyor belt\n",
        "- We can install a camera system above the belt, feeding images to a computer\n",
        "- We can configure a sorting system that can receive a signal to reroute any lemon that is considered bad"
      ],
      "id": "bb45ec2c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c78261bb"
      },
      "source": [
        "### What could be a problem here?\n",
        "\n",
        "👷 Think of this question and write your answer in the text cell below."
      ],
      "id": "c78261bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b34b2e3"
      },
      "source": [
        "[Double click here to edit this cell and and write your ideas.]"
      ],
      "id": "5b34b2e3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a521ce39"
      },
      "source": [
        "### How do we state this as a machine learning problem?\n",
        "- What inputs can we give the DL system?\n",
        "- What \"decision\" or prediction de we expect to get from the DL system?\n",
        "- What type of ML problem is it?\n",
        "- Type of data we need to feed the DL model?\n",
        "- What type of performance do we want to achieve? Is ther a minimum performance threshold to reach to succeed?\n",
        "\n",
        "👷 Think of this write your ideas below"
      ],
      "id": "a521ce39"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "483f362c"
      },
      "source": [
        "[Double click here to edit this cell and and write your ideas.]"
      ],
      "id": "483f362c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_43WehaAIR4L"
      },
      "source": [
        "##### ---------------------------------------------------------"
      ],
      "id": "_43WehaAIR4L"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8fcaf7c"
      },
      "source": [
        "## 2️⃣ Collect and Prepare Data, including Labeling"
      ],
      "id": "d8fcaf7c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "028a1cd5"
      },
      "outputs": [],
      "source": [
        "ml_process()"
      ],
      "id": "028a1cd5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d51ed498"
      },
      "source": [
        "To solve our ML problem, we need a dataset with the following information:\n",
        "- a set of images with lemons of good quality\n",
        "- a set of images with lemons that show quality problems (rot, ...)\n",
        "\n",
        "We should have between roughly 50 and 100 images for each set. We will need to clean up and delete some images from our set, it is safer to start with **100 or 150** images."
      ],
      "id": "d51ed498"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ed9d4bc"
      },
      "source": [
        "### Collect images from internet\n",
        "\n",
        "Quickest and simplest way to create an initial image dataset is to collect them online.\n",
        "- Search images with key words or search phrases.\n",
        "- Download images and organize them in classes/categories based on the searches.\n",
        "- 👍 : easy and fast. labeling is straigthforward if search well defined\n",
        "- 👎 : quality of the images depends of the quality of the search engine and the search phrases.\n",
        "\n",
        "Good for a baseline, and to explore how things work out. Then we will need to improve."
      ],
      "id": "5ed9d4bc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e0d9ba3"
      },
      "source": [
        "We will use [duckduckgo](https://duckduckgo.com/) search engine which provides good results and is easily reachable.\n",
        "><a href=\"https://duckduckgo.com\" target=\"_blank\"><img src=\"https://duckduckgo.com/assets/common/dax-logo.svg\" width=5%></a>\n",
        "\n",
        "We will do the following:\n",
        "1. Experiment directly on [duckduckgo](https://duckduckgo.com/) to craft a good search phrase for each class\n",
        "2. Use these two search phrases to scrape images and download them onto the server for furtehr use"
      ],
      "id": "4e0d9ba3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0902b73"
      },
      "source": [
        "#### Experiment with keywords\n",
        "\n",
        "Experiment on [duckduckgo](https://duckduckgo.com/) directly.\n",
        "\n",
        "The objective is to define one **search phrase** that generates a good set of images or faces with masks and one **search phrase** that generates a good set of images of faces with not mask. You will notice, for instance, that the search phrase `faces with no mask` will return lots of images with masks 🙁.\n",
        "\n",
        "For this simple exercise, select **one** search phrase for the class `with_mask` and **one** search phrase for the class `without_mask`. In practice we would conbine the results of several search phrases for each class.\n",
        "\n",
        "Do not worry if you get a few unrelated images, we will clean this up later."
      ],
      "id": "a0902b73"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93e0448e"
      },
      "source": [
        "#### Launch the scraper application\n",
        "Once you have a good phrase for each of our two classes, save them in the cell below for further use."
      ],
      "id": "93e0448e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2865c0e"
      },
      "outputs": [],
      "source": [
        "# Replace the phrase in red below by your phrase. Keep the appostrophes \" \"\n",
        "search_phrase_0 = \"write your search phrase here\"\n",
        "search_phrase_1 = \"write your search phrase here\""
      ],
      "id": "c2865c0e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Tips if you are stuck:</summary>\n",
        "<p><code>search_phrase_0 = \"lemon rotten\"</code></p>\n",
        "<p><code>search_phrase_1 = \"lemon whole\"</code></p>\n",
        "</details>"
      ],
      "metadata": {
        "id": "J911Dzj0s6he"
      },
      "id": "J911Dzj0s6he"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI-UAL2BLO57"
      },
      "source": [
        "Give a name for each of your classes. The simple implementation in this exercise require that the class name does not include spaces."
      ],
      "id": "uI-UAL2BLO57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNNhhAYuLHHD"
      },
      "outputs": [],
      "source": [
        "class_name_0 = \"bad\"  # for class 0 in the binary classifier\n",
        "class_name_1 = \"good\"   # for class 1 in the binary classifier"
      ],
      "id": "ZNNhhAYuLHHD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78a672f6"
      },
      "source": [
        "Pick a number of images to download for each class. You can define between 50 and 450 images to download for each class."
      ],
      "id": "78a672f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7c12017"
      },
      "outputs": [],
      "source": [
        "number_images_to_download = 100         # this can go up to 450 at the time of writing"
      ],
      "id": "f7c12017"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa7eafab"
      },
      "source": [
        "The cell below will automate the search and download process for you. It will:\n",
        "- create a path to the folder where we want the images to be saved\n",
        "- run the Duckduckgo search for the two classes classes\n",
        "- check that all images are correctly downloaded and delete any defective ones"
      ],
      "id": "fa7eafab"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_images(keywords, label, path, max_results=100):\n",
        "    results = DDGS().images(\n",
        "        keywords=keywords,\n",
        "        region=\"wt-wt\",\n",
        "        safesearch=\"on\",\n",
        "        size=None,\n",
        "        color=\"color\",\n",
        "        type_image='photo',\n",
        "        layout=None,\n",
        "        license_image=None,\n",
        "        max_results=max_results,\n",
        "    )\n",
        "    if len(results) == 0:\n",
        "        print(f\"Not images found for {keywords}\")\n",
        "    else:\n",
        "        path2imgs = path / label\n",
        "        os.makedirs(path2imgs, exist_ok=True)\n",
        "        urls = [r['image'] for r in results]\n",
        "        print(f\"Found {len(results)} images for label {label}. Downloading into {path2imgs.absolute()}\")\n",
        "        download_images(path2imgs, urls=urls)\n",
        "        print('All downloaded')"
      ],
      "metadata": {
        "id": "98Bym-Y5mH3C"
      },
      "id": "98Bym-Y5mH3C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_image_directory(path, verbose=False):\n",
        "    def check_img(img):\n",
        "        try: _ = Image.open(img)\n",
        "        except Exception as e:\n",
        "            img = str(img).replace(\" \",\"\\ \")\n",
        "            os.system(f\"rm -f {img}\");\n",
        "            print(f\"removing error img:{img}\")\n",
        "\n",
        "    for cls in path.iterdir():\n",
        "        for i, img in enumerate(cls.iterdir()):\n",
        "            if verbose: print(i, end=' - ')\n",
        "            check_img(img)\n",
        "            if verbose: print('\\n')"
      ],
      "metadata": {
        "id": "msla7gI33nE3"
      },
      "id": "msla7gI33nE3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rmtree('/content/images')"
      ],
      "metadata": {
        "id": "f1QCuhfexGTS"
      },
      "id": "f1QCuhfexGTS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf685cce"
      },
      "outputs": [],
      "source": [
        "path = Path()/ 'images'\n",
        "print(f\"All images will be saved into {path.absolute()}\")\n",
        "\n",
        "# Search and download\n",
        "get_images(keywords=search_phrase_0, label=class_name_0, path=path, max_results=number_images_to_download)\n",
        "get_images(keywords=search_phrase_1, label=class_name_1, path=path, max_results=number_images_to_download)\n",
        "\n",
        "# Check that all images can be used and delete any defective image"
      ],
      "id": "bf685cce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJxqK0sXL7Ia"
      },
      "outputs": [],
      "source": [
        "count_files(path)"
      ],
      "id": "kJxqK0sXL7Ia"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is the number of images not 100 for each class?\n",
        "- some images were deleted because we could not open the file\n",
        "- several links in the search results may have pointed to the same image file"
      ],
      "metadata": {
        "id": "TrrRLERvq1j3"
      },
      "id": "TrrRLERvq1j3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4781ff1"
      },
      "source": [
        "Now we have downloaded our images into a folder called `images` and\n",
        "- all images of for class with mask are grouped into `images/with_mask`\n",
        "- all images of faces without mask are grouped into `images/without_mask `\n",
        "\n",
        "We are ready to start with the model"
      ],
      "id": "d4781ff1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d87349e"
      },
      "source": [
        "### Prepare data to feed the model.\n",
        "Computer only do what they are told to do, therefore we need to tell it:\n",
        "- what type of data we use,\n",
        "- where it can find the data , and\n",
        "- what to do with it.\n",
        "\n",
        "We do that with a **`DataBlock`**."
      ],
      "id": "3d87349e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTWA4HaTC9VE"
      },
      "source": [
        "\n",
        "\n",
        "In this example, the code below tells the computer:\n",
        "- we have **images** as input\n",
        "- all images files are in a specific folder\n",
        "    - the computer retrieves images by using a function **`get_image_files`** which returns a list of all the images in a given folder\n",
        "- for each image, we have one *label* a.k.a. *class* a.k.a **`category`** a.k.a. **`y`**\n",
        "    - the computer will know which is the class of each image by looking in which **folder** it is located\n",
        "    - this is retrieved by using a function **`parent_label`**\n",
        "- before using each image, the computer should **resize** it into a standard square of size 128 pixels\n",
        "- finaly, we want to keep a **validation set** of 30% of the images. These images will **not** be used for training, but they are only used to test whether the trained model generalizes well on new images."
      ],
      "id": "WTWA4HaTC9VE"
    },
    {
      "cell_type": "code",
      "source": [
        "fn_list = get_image_files(path)\n",
        "fn_list[:3]"
      ],
      "metadata": {
        "id": "JtUzLJBXrHEw"
      },
      "id": "JtUzLJBXrHEw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parent_label(fn_list[0])"
      ],
      "metadata": {
        "id": "9ZtU2VXjrSKm"
      },
      "id": "9ZtU2VXjrSKm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ce8654a"
      },
      "outputs": [],
      "source": [
        "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
        "                   get_items=get_image_files,\n",
        "                   get_y=parent_label,\n",
        "                   item_tfms=Resize(128),\n",
        "                   splitter=RandomSplitter(valid_pct=0.30, seed=88),\n",
        "                   )"
      ],
      "id": "2ce8654a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "340ebeb1"
      },
      "source": [
        "Now the computer has a **recipe** to handle images in a specific folder. It has not done anything yet.\n",
        "\n",
        "We have put our images in `path`. Now we tell the computer to apply the recipe (`dblock`) to a specific folder (`path`):\n",
        "- go to `path`\n",
        "- identify all images there\n",
        "- build a dataset for training and a dataset for validation\n",
        "- get ready to resize the data\n",
        "- use the images in groups of 16 at the time\n",
        "\n",
        "What we get after that is called a **`dataloaders`** (`dls`) because it is the tool the computer will use to load data into the model. It is plural because there are two sets: training and validation."
      ],
      "id": "340ebeb1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpdufqnLzXsB"
      },
      "outputs": [],
      "source": [
        "path.absolute()"
      ],
      "id": "gpdufqnLzXsB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d37cd336"
      },
      "outputs": [],
      "source": [
        "dls = dblock.dataloaders(path, bs=16)"
      ],
      "id": "d37cd336"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b56a7ef"
      },
      "source": [
        "The `dataloaders` `dls` gives us access to all images. One thing we can do is to see a random sample of the images and their labels. We can play with the number of images to display (`max_n`)."
      ],
      "id": "2b56a7ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db656e8e"
      },
      "outputs": [],
      "source": [
        "dls.show_batch(max_n=24)"
      ],
      "id": "db656e8e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c36d67b7"
      },
      "source": [
        "### Clean up data\n",
        "Some of the images are not what we want, or are wrongly labeled. We can correct or remove them."
      ],
      "id": "c36d67b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEYmDg4dDBhc"
      },
      "source": [
        "Looking above, it clear that some of the images are not correct or not optimum for training. We need to delete some of them.\n",
        "- images with something not related to the class (e.g. mask but no face, ...)\n",
        "- images that are drawings and not real photos\n",
        "- multiple faces, ...\n",
        "\n",
        "It is a judgment call, there is no formal rule for that. Use common sense.\n",
        "\n",
        "To make this easier, we will use a tool called `display_image_cleaner`"
      ],
      "id": "EEYmDg4dDBhc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23146127"
      },
      "outputs": [],
      "source": [
        "display_image_cleaner(path)"
      ],
      "id": "23146127"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62t8JVW5Rxz0"
      },
      "outputs": [],
      "source": [
        "count_files(path)"
      ],
      "id": "62t8JVW5Rxz0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93db0e12"
      },
      "source": [
        "#### Update our `dataloaders`\n",
        "Our data are now cleaned up a little. We recreate our dataloaders, because we have deleted some images and it is important to refresh it all."
      ],
      "id": "93db0e12"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eb00453"
      },
      "outputs": [],
      "source": [
        "dls = dblock.dataloaders(path, bs=8)"
      ],
      "id": "7eb00453"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b92b5d50"
      },
      "source": [
        "Let's have a look at the images again"
      ],
      "id": "b92b5d50"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e837a175"
      },
      "outputs": [],
      "source": [
        "dls.show_batch(max_n=4)"
      ],
      "id": "e837a175"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac90f4cc"
      },
      "source": [
        "OK, this looks good enough for a first training run now."
      ],
      "id": "ac90f4cc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2df5a18"
      },
      "source": [
        "## 3️⃣ Build a model and train it"
      ],
      "id": "b2df5a18"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc2e6a48"
      },
      "outputs": [],
      "source": [
        "ml_process()"
      ],
      "id": "dc2e6a48"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f0c4594"
      },
      "source": [
        "We are ready to build the model.\n",
        "\n",
        "We will not build a neural network from scratch. Instead, we will use a **pre-trained models** and perform something called **transfer learning**.\n",
        "\n",
        "We use a model that has been trained on a very large number of images to solve a specific classification problem, and then we will finetune it for our own classification problem.\n",
        "\n",
        "Sounds like a big thing, but we will do this in two lines of code with `fastai`.\n",
        "\n"
      ],
      "id": "1f0c4594"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N0E3pR9GwZF"
      },
      "source": [
        "#### Architecture Selection\n"
      ],
      "id": "-N0E3pR9GwZF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd_kv_OkG0mE"
      },
      "source": [
        "We select: RESNET 18.\n",
        "> Resnet is a SOTA convolutional neural network (CNN), pre-trained on a large dataset called Imagenet, including 1,281,167 training images organized in 1,000 classes.\n",
        ">\n",
        "><img src=\"https://image-net.org/static_files/index_files/logo.jpg\" height=20px>\n",
        ">\n",
        "> CNNs are the currently go-to type of architectures for computer vision problem and Resnet is an excellent choice. Resnet comes in several versions, including\n",
        "> - resnet-18 with 18 layers\n",
        "> <div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/img/resnet-18-01.png\" width=75%></div>\n",
        "> - resnet-34 with 34 layers\n",
        "> <div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/img/resnet-34-01.png\" height=300px></div>\n",
        "> - resnet-50 with 50 layers"
      ],
      "id": "Kd_kv_OkG0mE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8f0f92b"
      },
      "source": [
        "#### Create a model CNN model for computer vision\n",
        "We create the model by telling the computer:\n",
        "- the **data** to use to train the model: `dls`\n",
        "- the **architecture** to use: `resnet18`. you can experiment with `resnet34` or `resnet50`.\n",
        "- the **metrics** we want to monitor to evaluate the performance. We will use the **accuracy**, **precision** and **recall**. More in this later\n",
        "\n",
        "The first time we run the cell, fastai will download the pretrained model parameters to use them. After that it will use the copy it has saved on disk."
      ],
      "id": "a8f0f92b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c02b85a9"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(\n",
        "    dls,\n",
        "    resnet18,\n",
        "    metrics=[accuracy, Precision(), Recall()]\n",
        "    );"
      ],
      "id": "c02b85a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "278170f8"
      },
      "source": [
        "#### Train - Finetune the model\n",
        "\n",
        "Now we are ready to train our model (`learner`).  As we use a pretrained model, we will **finetune** it.\n",
        "\n"
      ],
      "id": "278170f8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHMKIfpxT5hk"
      },
      "source": [
        "How does the model learn? Three levels of explanation"
      ],
      "id": "sHMKIfpxT5hk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouEZnMzAT4X6"
      },
      "source": [
        "###### Level 1\n"
      ],
      "id": "ouEZnMzAT4X6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxDEeEfzUIAU"
      },
      "source": [
        "The model learns by \"looking\" at each image several times and modifying its parameters to improve the match between its predicted outputs and the training labels.\n",
        "\n",
        "It is essentially an iterative optimization problem: what is the combination of parameter values that results to the best accuracy between predicted classes and labels (true class) across the training dataset and the validation dataset.\n",
        "\n",
        "When we have a model that shows good performances (training and validation accuracy), we \"hope\" that it has **generalized**. This means that it will also perform well on all new data."
      ],
      "id": "FxDEeEfzUIAU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8po3ow4zUkYU"
      },
      "source": [
        "###### Level 2\n"
      ],
      "id": "8po3ow4zUkYU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1KBf3LiWyTJ"
      },
      "source": [
        "The optimization process used for deep learning models is based on an iteration of **forward pass** and **back propagation pass**.\n",
        "\n",
        " <div align=\"center\"><img src=\"https://www.2diyai.com/guided-dive/resources/img/backpropagation-2.gif\" width=50%></div>\n",
        "\n",
        "- Take a number of images out of the training dataset (in our case 16), called a batch\n",
        "    - forward pass:\n",
        "        - calculate a prediction for image in this batch\n",
        "        - evaluate how remote the predictions are compared to the label provided in the training set (loss)\n",
        "    - back propagation pass:\n",
        "        - adjust all parameters to come closer to the correct prediction for all images in the batch, using the loss and its gradient w.r.t. each parameter.\n",
        "- Start again, until all images are seen."
      ],
      "id": "I1KBf3LiWyTJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTPWoMrZUnLl"
      },
      "source": [
        "-"
      ],
      "id": "JTPWoMrZUnLl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXzxJZjIUoWM"
      },
      "source": [
        "###### Level 3"
      ],
      "id": "iXzxJZjIUoWM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QahN4NlTbXN1"
      },
      "source": [
        "There are many options available to train a model, and the choice of these options will make the model train well or not. A good model will train well as it achieves good performances on the training and validation sets (generalizes).\n",
        "<div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/img/overfit-underfit.png\" width=70%></div>"
      ],
      "id": "QahN4NlTbXN1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNZ3G8aFKHlx"
      },
      "source": [
        "**Key options**:\n",
        "\n",
        "- Learning the best parameters is an optimization problem: define the parammeters which minimize the loss function\n",
        "<div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/img/sgd-1.png\" width=70%></div>\n",
        "\n",
        "\n",
        "- There are several optimizer algorithms available for training. Some are faster, some are less prone to fall in \"local minima\".\n",
        "<div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/img/optimizers-2.gif\" width=50%></div>\n",
        "\n",
        "\n",
        "- The single most important factor for training, beside the optimizer, is the Learning Rate\n",
        "<div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/img/lr.png\" width=80%></div>\n",
        "\n"
      ],
      "id": "rNZ3G8aFKHlx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkJB_iuqa1H2"
      },
      "source": [
        "###### Training vs Finetuning"
      ],
      "id": "ZkJB_iuqa1H2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofCn2CVIULzs"
      },
      "source": [
        "While training, the model \"sees\" all images in the training set, several times.\n",
        "\n",
        "In deep learning jargon, one iteration over which the model sees all images in the training set once is called an **`epoch`**.\n",
        "\n",
        "When models are trained from scratch, it is often necessary to use hundred or thousands of epochs. But in the case of a pre-trained model, a few epochs are often enough in first instance.\n",
        "\n"
      ],
      "id": "ofCn2CVIULzs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpmKOqVKK4kk"
      },
      "source": [
        "We run 5 or 10 epochs. But fee free to try less or more\n",
        "\n",
        "At the end of each epoch, the system returns information of the metrics:\n",
        "\n",
        "|epoch|train_loss|valid_loss|accuracy|precision_score|recall_score|time\n",
        "|-----|----------|----------|--------|---------------|------------|----\n",
        "0|1.081642|0.391084|0.833333|0.818182|0.818182|00:01\n",
        "\n",
        "Accuracy, Precision and Recall are the three metrics we will follow. The closet to one the better."
      ],
      "id": "PpmKOqVKK4kk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shi04SoCfPIV"
      },
      "source": [
        "Learning Rate (`lr`) is the single most important optimization parameter. It is the \"speed\" at which or \"extend\" to which the model correct itself at each iteration/pass. High learning rate train fast but also lead to divergence. Low learning rate make training very slow."
      ],
      "id": "shi04SoCfPIV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7N0y8iCeOTm"
      },
      "outputs": [],
      "source": [
        "lr = learn.lr_find(suggest_funcs=(SuggestionMethod.Valley, SuggestionMethod.Minimum, SuggestionMethod.Slide, SuggestionMethod.Steep))\n",
        "lr"
      ],
      "id": "f7N0y8iCeOTm"
    },
    {
      "cell_type": "code",
      "source": [
        "learn = vision_learner(\n",
        "    dls,\n",
        "    resnet18,\n",
        "    metrics=[accuracy, Precision(), Recall()]\n",
        "    );"
      ],
      "metadata": {
        "id": "fIWnysSstG9i"
      },
      "id": "fIWnysSstG9i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5187ff3"
      },
      "outputs": [],
      "source": [
        "nr_epochs = 10\n",
        "\n",
        "learn.fine_tune(nr_epochs, freeze_epochs=2, base_lr=lr.valley)"
      ],
      "id": "c5187ff3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e05b97c4"
      },
      "source": [
        "How good is our model? The metrics have improved during training, but is the final result a good one?"
      ],
      "id": "e05b97c4"
    },
    {
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_loss()"
      ],
      "metadata": {
        "id": "Ir9L4ybcP2bL"
      },
      "id": "Ir9L4ybcP2bL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "194924ae"
      },
      "source": [
        "## 4️⃣ Evaluate the trained model"
      ],
      "id": "194924ae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64901558"
      },
      "outputs": [],
      "source": [
        "ml_process()"
      ],
      "id": "64901558"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52881f31"
      },
      "source": [
        "### Evaluate based on the validation set"
      ],
      "id": "52881f31"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edb752e3"
      },
      "source": [
        "We have reserved about 30% of the images for `validation`, with is checking how the model performs on images it has not seen during training. If the model **generalizes**, the result of these images should be good as well.\n",
        "\n",
        "One good tool to evalute the model is to plot the confusion matrix:"
      ],
      "id": "edb752e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f9a69cf"
      },
      "outputs": [],
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "id": "3f9a69cf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ_902xfm2jm"
      },
      "outputs": [],
      "source": [
        "cm = interp.confusion_matrix()\n",
        "print_metrics(cm)"
      ],
      "id": "kJ_902xfm2jm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f31879b"
      },
      "source": [
        "We also can visualize the images where we have errors"
      ],
      "id": "5f31879b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28f52dec"
      },
      "outputs": [],
      "source": [
        "interp.plot_top_losses(k=6, figsize=(18,15))"
      ],
      "id": "28f52dec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "079f366c"
      },
      "source": [
        "### Evaluate with new data\n",
        "\n",
        "We only had a small set of unseen images (validation set).\n",
        "\n",
        "We should use a larger test set. We could download more images and create a bigger test set. But it hapens that there is a lemon dataset on Kaggle, which I have made available on AWS S3 for download.  It includes more than 2,000 labelled images. Let's use a subset of these to use as test set."
      ],
      "id": "079f366c"
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_ds = untar_data('https://diyai-dives.s3.ap-southeast-1.amazonaws.com/datasets/lemon-img-dataset.zip')\n",
        "path_to_ds"
      ],
      "metadata": {
        "id": "ZLIgNwr8vY5f"
      },
      "id": "ZLIgNwr8vY5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in path_to_ds.ls():\n",
        "    if 'quality' not in p.name: rmtree(p)\n",
        "    if 'quality' in p.name: shutil.move(p, p.parent / f\"{p.name.replace('_quality','')}\")\n",
        "\n",
        "path_to_ds.ls()"
      ],
      "metadata": {
        "id": "aJqUWWS-wlp9"
      },
      "id": "aJqUWWS-wlp9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rmtree(path_to_ds)"
      ],
      "metadata": {
        "id": "TgS5LC9bS0WE"
      },
      "id": "TgS5LC9bS0WE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c61f7bc"
      },
      "outputs": [],
      "source": [
        "test_path = path_to_ds\n",
        "count_files(test_path)"
      ],
      "id": "5c61f7bc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ba24f74"
      },
      "source": [
        "The code below randomly selects a small number of images from the huge dataset to use as a test set."
      ],
      "id": "1ba24f74"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61bd03b0"
      },
      "outputs": [],
      "source": [
        "nbr_test_images = 100\n",
        "\n",
        "test_image_fnames = get_image_files(test_path)\n",
        "idxs = np.random.choice(len(test_image_fnames)-1, nbr_test_images)\n",
        "test_image_fnames = test_image_fnames[idxs]"
      ],
      "id": "61bd03b0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8549e3a5"
      },
      "source": [
        "#### Create the test set\n",
        "Now we create a test dataset. To do so, we use the same dataloaders`dls` as before, but we tell the computer to look at the images from the list of image file names `test_image_fnames`, and to perform the same type of actions (recipe) as for the training dataset."
      ],
      "id": "8549e3a5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8cd2cce"
      },
      "outputs": [],
      "source": [
        "test_dl = dls.test_dl(test_image_fnames, with_labels=True)"
      ],
      "id": "c8cd2cce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff8c9a6f"
      },
      "outputs": [],
      "source": [
        "test_dl.show_batch(max_n=16)"
      ],
      "id": "ff8c9a6f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GCOv9BTLxMh"
      },
      "source": [
        "#### Predict and evaluate the test set"
      ],
      "id": "8GCOv9BTLxMh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb1abbac"
      },
      "source": [
        "Now we do the interpretation again, but using the test dataloader `test_dl`, instead of the validation set."
      ],
      "id": "cb1abbac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09258b9e"
      },
      "outputs": [],
      "source": [
        "test_results = learn.validate(dl=test_dl)\n",
        "for i, m in enumerate(learn.metrics):\n",
        "    print(f\"{m.name:16s}:  {test_results[i+1]*100:.1f}%\")"
      ],
      "id": "09258b9e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "912bd426"
      },
      "outputs": [],
      "source": [
        "interp_test = ClassificationInterpretation.from_learner(learn, dl=test_dl)"
      ],
      "id": "912bd426"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01af4380"
      },
      "outputs": [],
      "source": [
        "interp_test.plot_confusion_matrix()"
      ],
      "id": "01af4380"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUv5JaSdpUqu"
      },
      "outputs": [],
      "source": [
        "cm = interp.confusion_matrix()\n",
        "print_metrics(cm)"
      ],
      "id": "dUv5JaSdpUqu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dd7516f"
      },
      "source": [
        "**What to watch**:\n",
        "- Do we not let pass many people without a mask ?\n",
        "\n",
        "- Do we block many people with a mask ? This woult raise many complaints 💣 !"
      ],
      "id": "5dd7516f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7530c5df"
      },
      "source": [
        "Let's have a look at the biggest mistakes"
      ],
      "id": "7530c5df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "021147c7"
      },
      "outputs": [],
      "source": [
        "interp_test.plot_top_losses(k=9, figsize=(15, 15))"
      ],
      "id": "021147c7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cf080c5"
      },
      "source": [
        "It is clear that the model misses quite a few cases when the image is not that good. But a good model should be able to see that, we, humans, can."
      ],
      "id": "9cf080c5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20fe5e33"
      },
      "source": [
        "## 5️⃣ Improve the model by using more data"
      ],
      "id": "20fe5e33"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6f263a3"
      },
      "outputs": [],
      "source": [
        "ml_process()"
      ],
      "id": "c6f263a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3435d6e4"
      },
      "source": [
        "We have seen that we can get a decent model with only between 50 and 100 images of each class. But we also saw that the result need improvement. The best way to get more out of the model is to feed it more data.\n",
        "\n",
        "We could download 400 images and clean these, and then retrain the model.\n",
        "\n",
        "But let's go crazy !\n",
        "\n",
        "We will use the **Lemon** dataset already available on Kaggle. With 2,000 images, we are going all the way toward large dataset."
      ],
      "id": "3435d6e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e25194f0"
      },
      "source": [
        "### Create the dataloaders\n",
        "\n",
        "This is exactly the same recipe as before, except that we keep a vaidation set of 30% as we have more images in general."
      ],
      "id": "e25194f0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18fcc5d3"
      },
      "outputs": [],
      "source": [
        "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
        "                   get_items=get_image_files,\n",
        "                   get_y=parent_label,\n",
        "                   item_tfms=Resize(128),\n",
        "                   splitter=RandomSplitter(valid_pct=0.4, seed=42),\n",
        "                   )"
      ],
      "id": "18fcc5d3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23e33199"
      },
      "source": [
        "Now we apply this \"recipe\" to all images in the folder that includes all images of Facemask-44k. It will take a little while as there are many images."
      ],
      "id": "23e33199"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49bd8c86"
      },
      "outputs": [],
      "source": [
        "dls = dblock.dataloaders(path_to_ds, bs=32)"
      ],
      "id": "49bd8c86"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acc07dc0"
      },
      "outputs": [],
      "source": [
        "dls.show_batch(max_n=16)"
      ],
      "id": "acc07dc0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b73f189"
      },
      "source": [
        "## Create a new model and train it\n",
        "\n",
        "Be prepared, training will take longer then before. We have close to 300 times more images. You can count on 2 to 4 minutes per epoch.\n",
        "\n",
        "It is longer, but as a comparison, a full training from scratch of resnet would take something like **14 days** on a normal GPU like we have here.\n",
        "\n",
        "We create a model like before and then finetune it for 5 epochs"
      ],
      "id": "8b73f189"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2e0af77"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(\n",
        "    dls,\n",
        "    resnet18,\n",
        "    metrics=[accuracy, Precision(), Recall()]\n",
        "    )"
      ],
      "id": "c2e0af77"
    },
    {
      "cell_type": "code",
      "source": [
        "lr = learn.lr_find(suggest_funcs=[SuggestionMethod.Valley, SuggestionMethod.Minimum, SuggestionMethod.Slide, SuggestionMethod.Steep])"
      ],
      "metadata": {
        "id": "HidIxIaRzu_r"
      },
      "id": "HidIxIaRzu_r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KakcJ7_rXlsE"
      },
      "outputs": [],
      "source": [
        "learn.fine_tune(freeze_epochs=2, epochs=10, base_lr = lr.valley)"
      ],
      "id": "KakcJ7_rXlsE"
    },
    {
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_loss();"
      ],
      "metadata": {
        "id": "5Lqg04KN0FU-"
      },
      "id": "5Lqg04KN0FU-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fdeb6a4"
      },
      "source": [
        "### Evaluate the results"
      ],
      "id": "7fdeb6a4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3bdaf44"
      },
      "outputs": [],
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "id": "e3bdaf44"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cdc13af"
      },
      "source": [
        "👍 This is a much better performance. We still have a few mistakenly classified images but a much smaller percentage on a total of more than 13,000 images in the validation set (30% of 44,000).\n",
        "\n",
        "The metrics on the validation set are also much better:\n",
        "\n",
        "Model | Accuracy | Precision | Recall\n",
        ":-----|:--------:|:---------:|:-----:\n",
        "DGG   | 0.875000 | 0.833333  | 0.909091\n",
        "44k   | 0.980200 | 0.981170 | 0.978976\n",
        "\n",
        "\n",
        "We can expect much less complaints by management about wasting good lemons !\n",
        "\n",
        "In addition by looking at the top mistakes, it is clear that some of them are wrongly classified or just unclassifiable even by humans."
      ],
      "id": "4cdc13af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6848b79"
      },
      "outputs": [],
      "source": [
        "interp.plot_top_losses(k=4, figsize=(8, 8))"
      ],
      "id": "f6848b79"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "939da5f4"
      },
      "source": [
        "# Final comments and next step"
      ],
      "id": "939da5f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5c699b5"
      },
      "source": [
        "From here, there are many techniques to further improve and stress test the model. But this is beyond what we wanted you to experience during this session.\n",
        "\n",
        "The next steps, beside further improvement, will include:\n",
        "- saving the model so that it can be used by others\n",
        "- creating an application using the saved model and easiy classify new images.\n",
        "\n",
        "In our case, the application will be integrated into our existing temperature system and interface with the access control system. This is pure IT design, and will use the outcome of this discovery phase to build a strong and resilient model,"
      ],
      "id": "a5c699b5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5a0c380"
      },
      "source": [
        "Do not forget to save your notebook before you close this window."
      ],
      "id": "a5a0c380"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "d635b567",
        "50e0c1de",
        "90403b1e",
        "5873f103",
        "qMyORPPfGGRi",
        "bb45ec2c",
        "a0902b73",
        "ouEZnMzAT4X6",
        "8po3ow4zUkYU",
        "iXzxJZjIUoWM"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1341.270296,
      "end_time": "2021-09-12T09:20:50.567018",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-09-12T08:58:29.296722",
      "version": "2.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}